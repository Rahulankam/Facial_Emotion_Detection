{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fab2489e",
   "metadata": {},
   "source": [
    "# Emotion Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fcabf64",
   "metadata": {},
   "source": [
    "**Importing Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6901671",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e74b3e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version: 2.13.0\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "import cv2\n",
    "import random\n",
    "import os\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout, Flatten, Conv2D\n",
    "from tensorflow.keras.layers import BatchNormalization, Activation, MaxPooling2D\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "from IPython.display import SVG, Image\n",
    "import tensorflow as tf\n",
    "print(\"Tensorflow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9091ab7d",
   "metadata": {},
   "source": [
    "**Exploring Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b575611d",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = glob(\"train/**/**\")\n",
    "for i in range(9):\n",
    "    image = random.choice(images)\n",
    "    plt.figure(figsize=(12,12))\n",
    "    plt.subplot(331+i)\n",
    "    plt.imshow(cv2.imread(image));plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba16325a",
   "metadata": {},
   "source": [
    "**Preparing Data for Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45320a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 48\n",
    "batch_size = 64\n",
    "datagen_train = ImageDataGenerator()\n",
    "train_generator = datagen_train.flow_from_directory(\"train/\",\n",
    "                                                   target_size = (img_size,img_size),\n",
    "                                                   color_mode = \"grayscale\",\n",
    "                                                   batch_size = batch_size,\n",
    "                                                   class_mode = \"categorical\",\n",
    "                                                   shuffle = True)\n",
    "\n",
    "datagen_validation = ImageDataGenerator()\n",
    "validation_generator = datagen_train.flow_from_directory(\"test/\",\n",
    "                                                   target_size = (img_size,img_size),\n",
    "                                                   color_mode = \"grayscale\",\n",
    "                                                   batch_size = batch_size,\n",
    "                                                   class_mode = \"categorical\",\n",
    "                                                   shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b045f6dd",
   "metadata": {},
   "source": [
    "**Defining Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13c2f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Convolution(input_tensor, filters, kernel_size):\n",
    "    x = Conv2D(filters = filters, kernel_size = kernel_size, padding = \"same\")(input_tensor)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D(pool_size = (2,2))(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116cbf31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Dense_f(input_tensor, nodes):\n",
    "    x = Dense(nodes)(input_tensor)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf2be45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fer(input_shape):\n",
    "    inputs = Input(input_shape)\n",
    "    conv_1 = Convolution(inputs,32,(3,3))\n",
    "    conv_2 = Convolution(conv_1,64,(5,5))\n",
    "    conv_3 = Convolution(conv_2,128,(3,3))\n",
    "\n",
    "    flatten = Flatten()(conv_3)\n",
    "    \n",
    "    dense_1 = Dense_f(flatten,256)\n",
    "\n",
    "    output  = Dense(7, activation=\"softmax\")(dense_1)\n",
    "    model  =  Model(inputs=[inputs],outputs = [output])\n",
    "    \n",
    "    model.compile(loss=['categorical_crossentropy'] , optimizer = 'adam' , metrics =[\"accuracy\"])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc1245b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_fer((48,48,1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0175ace",
   "metadata": {},
   "source": [
    "**Initializing the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358ef08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 15\n",
    "steps_per_epoch = train_generator.n//train_generator.batch_size\n",
    "validation_steps = validation_generator.n//validation_generator.batch_size\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"model_weights.h5\", monitor  ='val_accuracy', save_weights_only = True, mode = 'max', verbose =1)\n",
    "callbacks = [checkpoint]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edeadc08",
   "metadata": {},
   "source": [
    "# Traning the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8021a8",
   "metadata": {},
   "source": [
    "**The next cell takes time to complete**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40b7418",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "x = train_generator,\n",
    "steps_per_epoch = steps_per_epoch,\n",
    "epochs = epochs,\n",
    "validation_data = validation_generator,\n",
    "validation_steps = validation_steps,\n",
    "callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9a3d19",
   "metadata": {},
   "source": [
    "**Model Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46371ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(validation_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7793c450",
   "metadata": {},
   "source": [
    "**Plotting Loss**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d82f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.legend(['Train','Validation'],loc = 'upper left')\n",
    "plt.subplots_adjust(top=1.0,bottom=0.0,right =0.95,left=0.0,hspace=0.25,wspace=0.35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51087b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.legend(['Train','Validation'],loc = 'upper left')\n",
    "plt.subplots_adjust(top=1.0,bottom=0.0,right =0.95,left=0.0,hspace=0.25,wspace=0.35)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c304077",
   "metadata": {},
   "source": [
    "**Saving Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506b54cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"model_a.json\",\"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ca4471",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
